{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Superpowered AI is a Knowledge Base as a Service (KBaaS) that provides a robust and efficient way to create, store, and query knowledge bases. In this tutorial, we will demonstrate how the query_passages endpoint can be used to efficiently search a webpage for information relevant to a specific query with a single API call.\n",
    "\n",
    "Autonomous agents like AutoGPT can navigate the web and gather relevant information and perform actions. One challenge with building this kind of agent is that many webpages have too much text to fit into the context window of LLMs like GPT-3 and GPT-4. Agents can only see what's in their context window, so that's a problem. How can we expand access to things that don't fit in context? The answer is semantic search. \n",
    "\n",
    "Generally this is done by breaking the text into chunks, creating vector embeddings for each chunk, uploading those vectors to a vector database, and then querying the database with the query embedding vector. For an application like web browsing, where you may never need to search that exact page again, this is a pretty inefficient way to do it. We've built a more efficient and cost-effective way to do this. You simply provide the query along with the content you want to search in a single API call, and then we return the most relevant text snippets, as well as an LLM-generated summary.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before we start, ensure you have the following:\n",
    "\n",
    "1. A Superpowered AI account with API keys (Sign up [here](https://superpowered.ai) for free access).\n",
    "2. Python 3 installed on your computer.\n",
    "3. `beautifulsoup4` and `requests` libraries installed (you can install them using `pip install beautifulsoup4 requests`).\n",
    "\n",
    "## Step-by-Step Tutorial\n",
    "\n",
    "### Step 1: Set up the environment\n",
    "\n",
    "First, we will set up the environment by importing the required libraries and initializing the Superpowered AI SDK with our API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superpowered import query_passages\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set API keys\n",
    "os.environ[\"SUPERPOWERED_API_KEY_ID\"] = \"YOUR_API_KEY_ID\"\n",
    "os.environ[\"SUPERPOWERED_API_KEY_SECRET\"] = \"YOUR_API_KEY_SECRET\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `\"YOUR_API_KEY_ID\"` and `\"YOUR_API_KEY_SECRET\"` with your actual API keys.\n",
    "\n",
    "### Step 2: Scrape the web page\n",
    "\n",
    "Next, we will scrape the content of a web page page using the `requests` library and `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Mont_Blanc\"\n",
    "\n",
    "# scrape the URL\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "body = soup.find('body')\n",
    "content = body.text\n",
    "\n",
    "print (content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if that doesn't work for the web page you want to scrape, you can use Selenium, which is slower but works for a much wider variety of websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "url = \"https://superpoweredai.notion.site\"\n",
    "\n",
    "@contextmanager\n",
    "def get_chrome_driver(options):\n",
    "    \"\"\"\n",
    "    context manager to ensure `driver.quit()` is called after execution\n",
    "    to avoid memory leaks and zombie processes\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome(\"/opt/chromedriver\", options=options)\n",
    "    try:\n",
    "        yield driver\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def get_title_and_content_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    get the human-readable text from the website\n",
    "\n",
    "    This will require us to first render the page using a headless browser\n",
    "    and then get the text from the page\n",
    "    \"\"\"\n",
    "\n",
    "    print('attempting to get title and content from url: ', url)\n",
    "\n",
    "    # Use a headless Chrome browser for rendering\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    with get_chrome_driver(options) as browser:\n",
    "        browser.set_page_load_timeout(20)\n",
    "\n",
    "        # Navigate to the URL and wait for the page to render\n",
    "        browser.get(url)\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Get the HTML code of the page\n",
    "        html = browser.page_source\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title = soup.title.string if soup.title is not None else url\n",
    "    content = soup.get_text()\n",
    "    print('length of content: ', len(content))\n",
    "\n",
    "    return title, content\n",
    "\n",
    "title, content = get_title_and_content_from_url(url)\n",
    "\n",
    "print (title)\n",
    "print (content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Query the scraped content\n",
    "\n",
    "Now, we will query the scraped content using the query_passages endpoint. We will ask the question, \"What is the name of the highest mountain in the Alps?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the name of the highest mountain in the Alps?\"\n",
    "response = query_passages(query=query, passages=[content], top_k=5, summarize_results=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_passages()` function takes the following parameters:\n",
    "\n",
    "- `query`: The question we want to ask.\n",
    "- `passages`: A list containing the content we want to search.\n",
    "- `top_k`: The number of top results to return.\n",
    "- `summarize_results`: Whether to extract and summarize the top results.\n",
    "\n",
    "### Step 4: Print the results\n",
    "\n",
    "Finally, we will print the summarized response and the top results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mont Blanc [1] is the highest mountain in the Alps and Western Europe, standing at 4,807.81 m (15,774 ft) above sea level. It is located on the French-Italian border and is the second-most prominent mountain in Europe [4]. The summit of Mont Blanc is a permanent ice cap, with temperatures around −20 °C (−4 °F) [3]. The mountain and its surrounding peaks can create their own weather patterns, with the summit being prone to strong winds and sudden weather changes [3].\n"
     ]
    }
   ],
   "source": [
    "print (response[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,result in enumerate(response[\"ranked_results\"]):\n",
    "    print (f\"Result {i+1}:\")\n",
    "    print (result[\"content\"])\n",
    "    print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44d0561a9d33f22b2e67e0485c48036e39d1c698628b030a9859974b559ff507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
